{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135d686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to predict petal_length from sepal length and sepal_width\n",
    "#We are going to use gradient descent. So the batch size is the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c40fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afc2a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the iris dataset\n",
    "df = pd.read_csv (\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef29e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:2]\n",
    "t = df.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b09111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train test datasets\n",
    "X_train, X_test, t_train, t_test = train_test_split(X,t,test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7118691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "t_train = np.asarray(t_train)\n",
    "t_test = np.asarray(t_test)\n",
    "t_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d290a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08186617  0.4171579 ]\n",
      " [ 1.1889116  -0.1767902 ]]\n",
      "[[0.59812466 0.59367936]]\n"
     ]
    }
   ],
   "source": [
    "#Now let's create the neural network\n",
    "#We have one hidden layer\n",
    "#Two input nodes, two nodes in the hidden layer and one node in the output layer\n",
    "# The activation function of the hidden layer is going to be the sigmoid function \n",
    "# In the output layer there won't be an activation function, since we have standard regression\n",
    "#    x1------>0------\\\n",
    "#                     0-->\n",
    "#    x2------>0------/\n",
    "#def init_params():\n",
    "    #Lets now create the weight matrix W1 for the first layer. W1 is a 2x2 matrix\n",
    "    # W1 = [[w11, w21]\n",
    "    #       [w12, w22]]\n",
    "W1 = np.random.normal(size=(2,2))\n",
    "\n",
    "    #Lets now create the weight matrix W2 for the second layer. W2 is a 1x2 matrix\n",
    "    # W2 = [[w11, w21]]\n",
    "\n",
    "W2 = np.random.normal(size=(1,2))\n",
    "    #return W1, W2\n",
    "print(W1)\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750f7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a: np.ndarray) -> np.ndarray:\n",
    "    z = 1 / (1 + np.exp(-a))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e49731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function delivers the array of outcomes when we apply the current params on the data X\n",
    "def forwardPassing(X: np.ndarray, W1: np.ndarray, W2: np.ndarray) -> tuple:\n",
    "    A1 = np.dot(W1, X.T)\n",
    "    Z1 = sigmoid(A1)\n",
    "    Z2 = np.dot(W2, Z1)\n",
    "    return A1, Z1, Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2506ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A1, Z1, Z2 = forwardPassing(X_train, W1, W2)\n",
    "#print((Z2 - t_train).shape)\n",
    "#print(Z1[0].T.shape)\n",
    "#print(((Z2 - t_train) * Z1[0]).shape)\n",
    "#X_train.shape\n",
    "#print(W2.T[0])\n",
    "#dw1_1 = W2.T[0] * np.dot((2 * (Z2 - t_train) * Z1[0] * (1 - Z1[0])), X_train)\n",
    "#dw1_2 = W2.T[1] * np.dot((2 * (Z2 - t_train) * Z1[1] * (1 - Z1[1])), X_train)\n",
    "#dW1 = np.vstack((dw1_1, dw1_2))\n",
    "#print(dW1)\n",
    "#print(dw1_1)\n",
    "#print(dw1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4f70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X: np.ndarray, t: np.ndarray, W1: np.ndarray, W2: np.ndarray) -> float: \n",
    "    return np.sum(np.square(forwardPassing(X, W1, W2)[2] - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c4bc05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177.6913811568188\n"
     ]
    }
   ],
   "source": [
    "print(loss(X_train, t_train, W1, W2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b6ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation(W1: np.ndarray, W2: np.ndarray, Z1: np.ndarray, Z2: np.ndarray, X: np.ndarray, t: np.ndarray) -> tuple:\n",
    "    dW2 = 2* np.dot((Z2 - t), Z1.T)\n",
    "    #print(dW2)\n",
    "    dw1_1 = W2.T[0] * np.dot((2 * (Z2 - t_train) * Z1[0] * (1 - Z1[0])), X)\n",
    "    dw1_2 = W2.T[1] * np.dot((2 * (Z2 - t_train) * Z1[1] * (1 - Z1[1])), X)\n",
    "    dW1 = np.vstack((dw1_1, dw1_2))\n",
    "    #print(dW1)\n",
    "    return dW1, dW2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccab7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dW1, dW2 = backPropagation(W1, W2, Z1, Z2, X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73094798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(W1: np.ndarray, W2: np.ndarray, dW1: np.ndarray, dW2: np.ndarray, alpha: float) -> tuple:\n",
    "    W1 = W1 - alpha * dW1 \n",
    "    W2 = W2 - alpha * dW2 \n",
    "    return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "868a9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(W1)\n",
    "#print(dW1)\n",
    "#updateParams(W1, W2, dW1, dW2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cd8ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X: np.ndarray, t: np.ndarray, W1: np.ndarray, W2: np.ndarray, iterations: int, alpha: float) -> np.ndarray:\n",
    "    for i in range(iterations):\n",
    "        A1, Z1, Z2 = forwardPassing(X, W1, W2)\n",
    "        dW1, dW2 = backPropagation(W1, W2, Z1, Z2, X, t)\n",
    "        W1, W2 = updateParams(W1, W2, dW1, dW2, alpha)\n",
    "        if i % 50 == 0:\n",
    "            print(\"The loss is:\")\n",
    "            print(loss(X, t, W1, W2))\n",
    "            print(\"\")\n",
    "    return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65a0724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is:\n",
      "1097.0566634915153\n",
      "\n",
      "The loss is:\n",
      "314.7472494444189\n",
      "\n",
      "The loss is:\n",
      "303.80779240750036\n",
      "\n",
      "The loss is:\n",
      "302.5534251540462\n",
      "\n",
      "The loss is:\n",
      "300.5259229547915\n",
      "\n",
      "The loss is:\n",
      "295.2153209099308\n",
      "\n",
      "The loss is:\n",
      "253.37240965828877\n",
      "\n",
      "The loss is:\n",
      "207.26313821083758\n",
      "\n",
      "The loss is:\n",
      "175.35022997396274\n",
      "\n",
      "The loss is:\n",
      "148.25066480961593\n",
      "\n",
      "The loss is:\n",
      "124.9339250787313\n",
      "\n",
      "The loss is:\n",
      "106.50257509286513\n",
      "\n",
      "The loss is:\n",
      "93.44620079501274\n",
      "\n",
      "The loss is:\n",
      "84.98793401329668\n",
      "\n",
      "The loss is:\n",
      "79.77164366198448\n",
      "\n",
      "The loss is:\n",
      "76.59606725870944\n",
      "\n",
      "The loss is:\n",
      "74.6327027029278\n",
      "\n",
      "The loss is:\n",
      "73.3722709796813\n",
      "\n",
      "The loss is:\n",
      "72.51821381957286\n",
      "\n",
      "The loss is:\n",
      "71.90175170866148\n",
      "\n",
      "The loss is:\n",
      "71.42737908138221\n",
      "\n",
      "The loss is:\n",
      "71.04084470292783\n",
      "\n",
      "The loss is:\n",
      "70.71104795585713\n",
      "\n",
      "The loss is:\n",
      "70.41993870094942\n",
      "\n",
      "The loss is:\n",
      "70.15687985734418\n",
      "\n",
      "The loss is:\n",
      "69.91547664075198\n",
      "\n",
      "The loss is:\n",
      "69.69177481920381\n",
      "\n",
      "The loss is:\n",
      "69.48322738624545\n",
      "\n",
      "The loss is:\n",
      "69.28809863030446\n",
      "\n",
      "The loss is:\n",
      "69.10512047131489\n",
      "\n",
      "The loss is:\n",
      "68.93329564342064\n",
      "\n",
      "The loss is:\n",
      "68.7717866154997\n",
      "\n",
      "The loss is:\n",
      "68.61985432444509\n",
      "\n",
      "The loss is:\n",
      "68.47682543856124\n",
      "\n",
      "The loss is:\n",
      "68.3420755516357\n",
      "\n",
      "The loss is:\n",
      "68.21502092541998\n",
      "\n",
      "The loss is:\n",
      "68.0951145458379\n",
      "\n",
      "The loss is:\n",
      "67.98184414580612\n",
      "\n",
      "The loss is:\n",
      "67.87473096075333\n",
      "\n",
      "The loss is:\n",
      "67.77332862112722\n",
      "\n",
      "The loss is:\n",
      "67.67722193680225\n",
      "\n",
      "The loss is:\n",
      "67.58602550893113\n",
      "\n",
      "The loss is:\n",
      "67.49938218844332\n",
      "\n",
      "The loss is:\n",
      "67.41696143147158\n",
      "\n",
      "The loss is:\n",
      "67.33845760662582\n",
      "\n",
      "The loss is:\n",
      "67.26358830199045\n",
      "\n",
      "The loss is:\n",
      "67.19209266884462\n",
      "\n",
      "The loss is:\n",
      "67.12372982822161\n",
      "\n",
      "The loss is:\n",
      "67.05827735712482\n",
      "\n",
      "The loss is:\n",
      "66.9955298639395\n",
      "\n",
      "The loss is:\n",
      "66.93529765720966\n",
      "\n",
      "The loss is:\n",
      "66.87740550818093\n",
      "\n",
      "The loss is:\n",
      "66.8216915049794\n",
      "\n",
      "The loss is:\n",
      "66.76800599468919\n",
      "\n",
      "The loss is:\n",
      "66.71621060864265\n",
      "\n",
      "The loss is:\n",
      "66.6661773657492\n",
      "\n",
      "The loss is:\n",
      "66.61778784850927\n",
      "\n",
      "The loss is:\n",
      "66.57093244638895\n",
      "\n",
      "The loss is:\n",
      "66.52550966138858\n",
      "\n",
      "The loss is:\n",
      "66.48142547087613\n",
      "\n",
      "The loss is:\n",
      "66.4385927430393\n",
      "\n",
      "The loss is:\n",
      "66.3969307006133\n",
      "\n",
      "The loss is:\n",
      "66.35636442884982\n",
      "\n",
      "The loss is:\n",
      "66.31682442399772\n",
      "\n",
      "The loss is:\n",
      "66.27824617885882\n",
      "\n",
      "The loss is:\n",
      "66.2405698022617\n",
      "\n",
      "The loss is:\n",
      "66.20373966955745\n",
      "\n",
      "The loss is:\n",
      "66.16770410148737\n",
      "\n",
      "The loss is:\n",
      "66.13241506899811\n",
      "\n",
      "The loss is:\n",
      "66.09782792178942\n",
      "\n",
      "The loss is:\n",
      "66.06390113857321\n",
      "\n",
      "The loss is:\n",
      "66.03059609719796\n",
      "\n",
      "The loss is:\n",
      "65.99787686295541\n",
      "\n",
      "The loss is:\n",
      "65.96570999353432\n",
      "\n",
      "The loss is:\n",
      "65.93406435922051\n",
      "\n",
      "The loss is:\n",
      "65.9029109770662\n",
      "\n",
      "The loss is:\n",
      "65.87222285786343\n",
      "\n",
      "The loss is:\n",
      "65.8419748648594\n",
      "\n",
      "The loss is:\n",
      "65.81214358324308\n",
      "\n",
      "The loss is:\n",
      "65.78270719951863\n",
      "\n",
      "The loss is:\n",
      "65.75364538995727\n",
      "\n",
      "The loss is:\n",
      "65.72493921738948\n",
      "\n",
      "The loss is:\n",
      "65.69657103566361\n",
      "\n",
      "The loss is:\n",
      "65.66852440115406\n",
      "\n",
      "The loss is:\n",
      "65.64078399075576\n",
      "\n",
      "The loss is:\n",
      "65.61333552584975\n",
      "\n",
      "The loss is:\n",
      "65.58616570176737\n",
      "\n",
      "The loss is:\n",
      "65.55926212232151\n",
      "\n",
      "The loss is:\n",
      "65.53261323900966\n",
      "\n",
      "The loss is:\n",
      "65.50620829452484\n",
      "\n",
      "The loss is:\n",
      "65.48003727024329\n",
      "\n",
      "The loss is:\n",
      "65.45409083738309\n",
      "\n",
      "The loss is:\n",
      "65.42836031155392\n",
      "\n",
      "The loss is:\n",
      "65.40283761044071\n",
      "\n",
      "The loss is:\n",
      "65.37751521438577\n",
      "\n",
      "The loss is:\n",
      "65.35238612965114\n",
      "\n",
      "The loss is:\n",
      "65.32744385416271\n",
      "\n",
      "The loss is:\n",
      "65.30268234555177\n",
      "\n",
      "The loss is:\n",
      "65.27809599132529\n",
      "\n",
      "The loss is:\n",
      "65.25367958100917\n",
      "\n",
      "The loss is:\n",
      "65.2294282801212\n",
      "\n",
      "The loss is:\n",
      "65.20533760584178\n",
      "\n",
      "The loss is:\n",
      "65.18140340425995\n",
      "\n",
      "The loss is:\n",
      "65.15762182908325\n",
      "\n",
      "The loss is:\n",
      "65.13398932170705\n",
      "\n",
      "The loss is:\n",
      "65.11050259254756\n",
      "\n",
      "The loss is:\n",
      "65.0871586035513\n",
      "\n",
      "The loss is:\n",
      "65.06395455179745\n",
      "\n",
      "The loss is:\n",
      "65.0408878541193\n",
      "\n",
      "The loss is:\n",
      "65.01795613267436\n",
      "\n",
      "The loss is:\n",
      "64.99515720139821\n",
      "\n",
      "The loss is:\n",
      "64.97248905328334\n",
      "\n",
      "The loss is:\n",
      "64.9499498484268\n",
      "\n",
      "The loss is:\n",
      "64.92753790279626\n",
      "\n",
      "The loss is:\n",
      "64.90525167766641\n",
      "\n",
      "The loss is:\n",
      "64.8830897696827\n",
      "\n",
      "The loss is:\n",
      "64.86105090151074\n",
      "\n",
      "The loss is:\n",
      "64.83913391303464\n",
      "\n",
      "The loss is:\n",
      "64.8173377530689\n",
      "\n",
      "The loss is:\n",
      "64.7956614715511\n",
      "\n",
      "The loss is:\n",
      "64.77410421218632\n",
      "\n",
      "The loss is:\n",
      "64.75266520551423\n",
      "\n",
      "The loss is:\n",
      "64.73134376237398\n",
      "\n",
      "The loss is:\n",
      "64.71013926774212\n",
      "\n",
      "The loss is:\n",
      "64.68905117492145\n",
      "\n",
      "The loss is:\n",
      "64.66807900006016\n",
      "\n",
      "The loss is:\n",
      "64.6472223169819\n",
      "\n",
      "The loss is:\n",
      "64.62648075230855\n",
      "\n",
      "The loss is:\n",
      "64.60585398085941\n",
      "\n",
      "The loss is:\n",
      "64.58534172131102\n",
      "\n",
      "The loss is:\n",
      "64.56494373210302\n",
      "\n",
      "The loss is:\n",
      "64.54465980757679\n",
      "\n",
      "The loss is:\n",
      "64.52448977433417\n",
      "\n",
      "The loss is:\n",
      "64.50443348780443\n",
      "\n",
      "The loss is:\n",
      "64.48449082900859\n",
      "\n",
      "The loss is:\n",
      "64.46466170151095\n",
      "\n",
      "The loss is:\n",
      "64.4449460285479\n",
      "\n",
      "The loss is:\n",
      "64.42534375032554\n",
      "\n",
      "The loss is:\n",
      "64.40585482147705\n",
      "\n",
      "The loss is:\n",
      "64.38647920867265\n",
      "\n",
      "The loss is:\n",
      "64.36721688837397\n",
      "\n",
      "The loss is:\n",
      "64.3480678447267\n",
      "\n",
      "The loss is:\n",
      "64.32903206758397\n",
      "\n",
      "The loss is:\n",
      "64.31010955065534\n",
      "\n",
      "The loss is:\n",
      "64.29130028977485\n",
      "\n",
      "The loss is:\n",
      "64.27260428128261\n",
      "\n",
      "The loss is:\n",
      "64.25402152051545\n",
      "\n",
      "The loss is:\n",
      "64.2355520004006\n",
      "\n",
      "The loss is:\n",
      "64.21719571014881\n",
      "\n",
      "The loss is:\n",
      "64.19895263404146\n",
      "\n",
      "The loss is:\n",
      "64.18082275030837\n",
      "\n",
      "The loss is:\n",
      "64.16280603009143\n",
      "\n",
      "The loss is:\n",
      "64.14490243649075\n",
      "\n",
      "The loss is:\n",
      "64.12711192368941\n",
      "\n",
      "The loss is:\n",
      "64.10943443615332\n",
      "\n",
      "The loss is:\n",
      "64.09186990790286\n",
      "\n",
      "The loss is:\n",
      "64.07441826185294\n",
      "\n",
      "The loss is:\n",
      "64.05707940921839\n",
      "\n",
      "The loss is:\n",
      "64.03985324898191\n",
      "\n",
      "The loss is:\n",
      "64.02273966742122\n",
      "\n",
      "The loss is:\n",
      "64.00573853769299\n",
      "\n",
      "The loss is:\n",
      "63.98884971947092\n",
      "\n",
      "The loss is:\n",
      "63.97207305863477\n",
      "\n",
      "The loss is:\n",
      "63.95540838700874\n",
      "\n",
      "The loss is:\n",
      "63.938855522145865\n",
      "\n",
      "The loss is:\n",
      "63.922414267156675\n",
      "\n",
      "The loss is:\n",
      "63.90608441057955\n",
      "\n",
      "The loss is:\n",
      "63.88986572629071\n",
      "\n",
      "The loss is:\n",
      "63.87375797345156\n",
      "\n",
      "The loss is:\n",
      "63.85776089649129\n",
      "\n",
      "The loss is:\n",
      "63.841874225123064\n",
      "\n",
      "The loss is:\n",
      "63.826097674391114\n",
      "\n",
      "The loss is:\n",
      "63.81043094474786\n",
      "\n",
      "The loss is:\n",
      "63.79487372215822\n",
      "\n",
      "The loss is:\n",
      "63.77942567823002\n",
      "\n",
      "The loss is:\n",
      "63.764086470368575\n",
      "\n",
      "The loss is:\n",
      "63.74885574195342\n",
      "\n",
      "The loss is:\n",
      "63.733733122536385\n",
      "\n",
      "The loss is:\n",
      "63.71871822805869\n",
      "\n",
      "The loss is:\n",
      "63.70381066108586\n",
      "\n",
      "The loss is:\n",
      "63.68901001105917\n",
      "\n",
      "The loss is:\n",
      "63.67431585456182\n",
      "\n",
      "The loss is:\n",
      "63.65972775559911\n",
      "\n",
      "The loss is:\n",
      "63.64524526589039\n",
      "\n",
      "The loss is:\n",
      "63.63086792517275\n",
      "\n",
      "The loss is:\n",
      "63.61659526151405\n",
      "\n",
      "The loss is:\n",
      "63.602426791634976\n",
      "\n",
      "The loss is:\n",
      "63.588362021238744\n",
      "\n",
      "The loss is:\n",
      "63.57440044534735\n",
      "\n",
      "The loss is:\n",
      "63.56054154864339\n",
      "\n",
      "The loss is:\n",
      "63.54678480581665\n",
      "\n",
      "The loss is:\n",
      "63.53312968191429\n",
      "\n",
      "The loss is:\n",
      "63.51957563269399\n",
      "\n",
      "The loss is:\n",
      "63.50612210497928\n",
      "\n",
      "The loss is:\n",
      "63.49276853701578\n",
      "\n",
      "The loss is:\n",
      "63.47951435882848\n",
      "\n",
      "The loss is:\n",
      "63.466358992578456\n",
      "\n",
      "The loss is:\n",
      "63.45330185291916\n",
      "\n",
      "The loss is:\n",
      "63.44034234735094\n",
      "\n",
      "The loss is:\n",
      "63.42747987657393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W1, W2 = gradientDescent(X_train, t_train, W1, W2, 10000, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3654359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.289257559869506\n"
     ]
    }
   ],
   "source": [
    "print(loss(X_test, t_test, W1, W2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5307c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 1)\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "print(forwardPassing(X_test, W1, W2)[2].T.shape)\n",
    "print(len(t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "279e1d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8780721375081509\n",
      "0.33976127910821124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print(r2_score(forwardPassing(X_test, W1, W2)[2].T, t_test))\n",
    "print(mean_squared_error(forwardPassing(X_test, W1, W2)[2].T, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379dba9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e69f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
