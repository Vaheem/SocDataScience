{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Introduction to Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples: Linear Regression With Statsmodels\n",
    "\n",
    "Next to ```scikit-learn```, ```statsmodels``` is probably the most popular Python package for regression. While the focus of ```scikit-learn``` (will be covered next week) rather lies on machine learning applications, ```statsmodels``` (as the name suggests) has a rather statitics-oriented focus. We will briefly present the basic functionality of its regression functions by revisiting the Iris data set.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "df = pd.read_csv (\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Bivariate Prediction\n",
    "We want to fit a regession model that estimates sepal length from sepal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahee\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  sepal_width\n",
       "0    1.0          3.5\n",
       "1    1.0          3.0\n",
       "2    1.0          3.2\n",
       "3    1.0          3.1\n",
       "4    1.0          3.6\n",
       "5    1.0          3.9\n",
       "6    1.0          3.4\n",
       "7    1.0          3.4\n",
       "8    1.0          2.9\n",
       "9    1.0          3.1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify predictors X and target Y\n",
    "y = df.sepal_length\n",
    "X = df.sepal_width\n",
    "#print(X[:10])\n",
    "# most importantly: we have to add a constant term to estimate the intercept\n",
    "X = sm.add_constant(X)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>sepal_length</td>   <th>  R-squared:         </th> <td>   0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 04 Sep 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.183</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:18:51</td>     <th>  Log-Likelihood:    </th> <td> -183.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>   370.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   148</td>      <th>  BIC:               </th> <td>   376.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>    6.4812</td> <td>    0.481</td> <td>   13.466</td> <td> 0.000</td> <td>    5.530</td> <td>    7.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal_width</th> <td>   -0.2089</td> <td>    0.156</td> <td>   -1.339</td> <td> 0.183</td> <td>   -0.517</td> <td>    0.099</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.455</td> <th>  Durbin-Watson:     </th> <td>   0.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.108</td> <th>  Jarque-Bera (JB):  </th> <td>   4.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.356</td> <th>  Prob(JB):          </th> <td>   0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.585</td> <th>  Cond. No.          </th> <td>    24.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           sepal_length   R-squared:                       0.012\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     1.792\n",
       "Date:                Sun, 04 Sep 2022   Prob (F-statistic):              0.183\n",
       "Time:                        19:18:51   Log-Likelihood:                -183.14\n",
       "No. Observations:                 150   AIC:                             370.3\n",
       "Df Residuals:                     148   BIC:                             376.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const           6.4812      0.481     13.466      0.000       5.530       7.432\n",
       "sepal_width    -0.2089      0.156     -1.339      0.183      -0.517       0.099\n",
       "==============================================================================\n",
       "Omnibus:                        4.455   Durbin-Watson:                   0.941\n",
       "Prob(Omnibus):                  0.108   Jarque-Bera (JB):                4.252\n",
       "Skew:                           0.356   Prob(JB):                        0.119\n",
       "Kurtosis:                       2.585   Cond. No.                         24.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model: OLS = ordinary least squares\n",
    "model = sm.OLS(y,X)\n",
    "# fit model: only now te model, i.e. the parameters are computed\n",
    "results = model.fit()\n",
    "\n",
    "# print a summary, i.e. an overview on parameters and diagnostics\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const          6.481223\n",
       "sepal_width   -0.208870\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get parameters of model, i.e. beta_0 and beta_1\n",
    "params = results.params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.75017718 5.85461233 5.81283827 5.8337253  5.72929015 5.66662906\n",
      " 5.77106421 5.77106421 5.87549936 5.8337253  5.70840312 5.77106421\n",
      " 5.85461233 5.85461233 5.64574204 5.56219392 5.66662906 5.75017718\n",
      " 5.68751609 5.68751609 5.77106421 5.70840312 5.72929015 5.79195124\n",
      " 5.77106421 5.85461233 5.77106421 5.75017718 5.77106421 5.81283827\n",
      " 5.8337253  5.77106421 5.62485501 5.60396798 5.8337253  5.81283827\n",
      " 5.75017718 5.8337253  5.85461233 5.77106421 5.75017718 6.00082154\n",
      " 5.81283827 5.75017718 5.68751609 5.85461233 5.68751609 5.81283827\n",
      " 5.70840312 5.79195124 5.81283827 5.81283827 5.8337253  6.00082154\n",
      " 5.89638639 5.89638639 5.79195124 5.97993451 5.87549936 5.91727342\n",
      " 6.06348262 5.85461233 6.02170856 5.87549936 5.87549936 5.8337253\n",
      " 5.85461233 5.91727342 6.02170856 5.95904748 5.81283827 5.89638639\n",
      " 5.95904748 5.89638639 5.87549936 5.85461233 5.89638639 5.85461233\n",
      " 5.87549936 5.93816045 5.97993451 5.97993451 5.91727342 5.91727342\n",
      " 5.85461233 5.77106421 5.8337253  6.00082154 5.85461233 5.95904748\n",
      " 5.93816045 5.85461233 5.93816045 6.00082154 5.91727342 5.85461233\n",
      " 5.87549936 5.87549936 5.95904748 5.89638639 5.79195124 5.91727342\n",
      " 5.85461233 5.87549936 5.85461233 5.85461233 5.95904748 5.87549936\n",
      " 5.95904748 5.72929015 5.81283827 5.91727342 5.85461233 5.95904748\n",
      " 5.89638639 5.81283827 5.85461233 5.68751609 5.93816045 6.02170856\n",
      " 5.81283827 5.89638639 5.89638639 5.91727342 5.79195124 5.81283827\n",
      " 5.89638639 5.85461233 5.89638639 5.85461233 5.89638639 5.68751609\n",
      " 5.89638639 5.89638639 5.93816045 5.85461233 5.77106421 5.8337253\n",
      " 5.85461233 5.8337253  5.8337253  5.8337253  5.91727342 5.81283827\n",
      " 5.79195124 5.85461233 5.95904748 5.85461233 5.77106421 5.85461233]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      5.750177\n",
       "1      5.854612\n",
       "2      5.812838\n",
       "3      5.833725\n",
       "4      5.729290\n",
       "         ...   \n",
       "145    5.854612\n",
       "146    5.959047\n",
       "147    5.854612\n",
       "148    5.771064\n",
       "149    5.854612\n",
       "Length: 150, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can apply parameters to obtain the predictions of Y based on X\n",
    "print(np.dot(X,params))\n",
    "# unsurprisingly, statsmodels also provides a direct prediction function:\n",
    "results.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Multivariate Regression\n",
    "Now we want to include all other numerical columns from the data to fit to estimate sepal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>sepal_length</td>   <th>  R-squared:         </th> <td>   0.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   297.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 04 Sep 2022</td> <th>  Prob (F-statistic):</th> <td>6.28e-62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:18:56</td>     <th>  Log-Likelihood:    </th> <td> -37.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>   82.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   146</td>      <th>  BIC:               </th> <td>   94.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>    1.8451</td> <td>    0.250</td> <td>    7.368</td> <td> 0.000</td> <td>    1.350</td> <td>    2.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal_width</th>  <td>    0.6549</td> <td>    0.067</td> <td>    9.823</td> <td> 0.000</td> <td>    0.523</td> <td>    0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>petal_width</th>  <td>   -0.5626</td> <td>    0.127</td> <td>   -4.426</td> <td> 0.000</td> <td>   -0.814</td> <td>   -0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>petal_length</th> <td>    0.7111</td> <td>    0.057</td> <td>   12.560</td> <td> 0.000</td> <td>    0.599</td> <td>    0.823</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.265</td> <th>  Durbin-Watson:     </th> <td>   2.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.876</td> <th>  Jarque-Bera (JB):  </th> <td>   0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.003</td> <th>  Prob(JB):          </th> <td>   0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.737</td> <th>  Cond. No.          </th> <td>    54.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           sepal_length   R-squared:                       0.859\n",
       "Model:                            OLS   Adj. R-squared:                  0.856\n",
       "Method:                 Least Squares   F-statistic:                     297.0\n",
       "Date:                Sun, 04 Sep 2022   Prob (F-statistic):           6.28e-62\n",
       "Time:                        19:18:56   Log-Likelihood:                -37.000\n",
       "No. Observations:                 150   AIC:                             82.00\n",
       "Df Residuals:                     146   BIC:                             94.04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept        1.8451      0.250      7.368      0.000       1.350       2.340\n",
       "sepal_width      0.6549      0.067      9.823      0.000       0.523       0.787\n",
       "petal_width     -0.5626      0.127     -4.426      0.000      -0.814      -0.311\n",
       "petal_length     0.7111      0.057     12.560      0.000       0.599       0.823\n",
       "==============================================================================\n",
       "Omnibus:                        0.265   Durbin-Watson:                   2.053\n",
       "Prob(Omnibus):                  0.876   Jarque-Bera (JB):                0.432\n",
       "Skew:                           0.003   Prob(JB):                        0.806\n",
       "Kurtosis:                       2.737   Cond. No.                         54.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statsmodels also provides a formula syntax, which requires an additional import\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# formula syntax: dependent variable ~ predictor1 + predictor2 +.....\n",
    "# note that intercept is fit automatically\n",
    "model = ols(\"sepal_length ~ sepal_width + petal_width + petal_length\", data=df)\n",
    "\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>sepal_length</td>   <th>  R-squared:         </th> <td>   0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   186.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 04 Sep 2022</td> <th>  Prob (F-statistic):</th> <td>4.20e-61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:18:57</td>     <th>  Log-Likelihood:    </th> <td> -33.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>   78.06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   144</td>      <th>  BIC:               </th> <td>   96.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>    2.0983</td> <td>    0.476</td> <td>    4.408</td> <td> 0.000</td> <td>    1.157</td> <td>    3.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal_width:petal_width</th> <td>   -0.1255</td> <td>    0.100</td> <td>   -1.250</td> <td> 0.213</td> <td>   -0.324</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.square(petal_length)</th> <td>    0.0333</td> <td>    0.013</td> <td>    2.571</td> <td> 0.011</td> <td>    0.008</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal_width</th>             <td>    0.6790</td> <td>    0.123</td> <td>    5.541</td> <td> 0.000</td> <td>    0.437</td> <td>    0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>petal_width</th>             <td>   -0.1154</td> <td>    0.344</td> <td>   -0.335</td> <td> 0.738</td> <td>   -0.796</td> <td>    0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>petal_length</th>            <td>    0.4470</td> <td>    0.117</td> <td>    3.821</td> <td> 0.000</td> <td>    0.216</td> <td>    0.678</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.119</td> <th>  Durbin-Watson:     </th> <td>   1.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.942</td> <th>  Jarque-Bera (JB):  </th> <td>   0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.021</td> <th>  Prob(JB):          </th> <td>   0.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.794</td> <th>  Cond. No.          </th> <td>    483.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           sepal_length   R-squared:                       0.866\n",
       "Model:                            OLS   Adj. R-squared:                  0.862\n",
       "Method:                 Least Squares   F-statistic:                     186.9\n",
       "Date:                Sun, 04 Sep 2022   Prob (F-statistic):           4.20e-61\n",
       "Time:                        19:18:57   Log-Likelihood:                -33.031\n",
       "No. Observations:                 150   AIC:                             78.06\n",
       "Df Residuals:                     144   BIC:                             96.13\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                   2.0983      0.476      4.408      0.000       1.157       3.039\n",
       "sepal_width:petal_width    -0.1255      0.100     -1.250      0.213      -0.324       0.073\n",
       "np.square(petal_length)     0.0333      0.013      2.571      0.011       0.008       0.059\n",
       "sepal_width                 0.6790      0.123      5.541      0.000       0.437       0.921\n",
       "petal_width                -0.1154      0.344     -0.335      0.738      -0.796       0.565\n",
       "petal_length                0.4470      0.117      3.821      0.000       0.216       0.678\n",
       "==============================================================================\n",
       "Omnibus:                        0.119   Durbin-Watson:                   1.996\n",
       "Prob(Omnibus):                  0.942   Jarque-Bera (JB):                0.276\n",
       "Skew:                           0.021   Prob(JB):                        0.871\n",
       "Kurtosis:                       2.794   Cond. No.                         483.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formula syntax: dependent variable ~ predictor1 + predictor2 +.....\n",
    "# note that intercept is fit automatically\n",
    "\n",
    "# add interaction and squared term\n",
    "model = ols(\"sepal_length ~ sepal_width:petal_width + np.square(petal_length) + sepal_width + petal_width + petal_length\", data=df)\n",
    "\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Fitting an Artificial Data Set\n",
    "\n",
    "We want to implement OLS regression and test it on artificial data. Thus, in this task you may not yet use the `statsmodels` functions (except for checking results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Creating artificial data\n",
    "Create an artificial dataset which consists of:\n",
    "* a vector $x$ consisting of 100 (float) values between 0 and 1\n",
    "* a vector $y = 10x +\\varepsilon$, in which for each element, the error $\\varepsilon_i$ is drawn from the standard normal distribution.\n",
    "Create a scatterplot of x against y!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.412088965518262,\n",
       " 4.17011724715246,\n",
       " 0.4527071424380372,\n",
       " 1.868904928438841,\n",
       " 3.370402551314641,\n",
       " 0.1705221819044932,\n",
       " 2.95697362988258,\n",
       " 8.421763269007402,\n",
       " 2.695997168686625,\n",
       " 9.45794350537482,\n",
       " 1.4088431884753092,\n",
       " 1.2751644177536872,\n",
       " 3.9237935404096937,\n",
       " 6.271944018973317,\n",
       " 0.934401160745794,\n",
       " 5.5065755345362835,\n",
       " 4.836801118208511,\n",
       " 1.3633437623694198,\n",
       " 6.545386493653456,\n",
       " 2.3619529503234737,\n",
       " 2.1725995715798665,\n",
       " 8.914722892702084,\n",
       " 2.2176079084138,\n",
       " 0.6357530530472852,\n",
       " 7.473907486236018,\n",
       " 5.275582821715281,\n",
       " 3.3368497894646705,\n",
       " 7.384308246352183,\n",
       " 4.755261360868804,\n",
       " 0.19071340408594128,\n",
       " 7.095914476183195,\n",
       " 7.10710088433164,\n",
       " 8.653637497790118,\n",
       " 2.236149128207831,\n",
       " 3.1168809058913642,\n",
       " 4.920139510448155,\n",
       " 8.33700428778513,\n",
       " 8.282358736406888,\n",
       " 9.85396649976619,\n",
       " -1.409707415192136,\n",
       " 2.42663710128305,\n",
       " 7.824957680120177,\n",
       " 1.8534663899025299,\n",
       " 3.9492977024818536,\n",
       " 6.005462071189136,\n",
       " 1.5844458723125854,\n",
       " 6.242034554934992,\n",
       " 8.509606309625353,\n",
       " 4.329450644072513,\n",
       " 6.088827107742125,\n",
       " 3.4760720918511385,\n",
       " 2.8972232707350107,\n",
       " 2.726380841461599,\n",
       " 3.983216929662846,\n",
       " 6.2304270377831825,\n",
       " 4.505681942209897,\n",
       " 7.263652929402464,\n",
       " 6.3698244235105,\n",
       " 2.820780841571152,\n",
       " 3.5731545509739124,\n",
       " 9.611072515650624,\n",
       " 9.152924925290751,\n",
       " 5.461986297244971,\n",
       " 2.7903910371789395,\n",
       " 7.010595935788263,\n",
       " 4.653923019848784,\n",
       " 8.266023614717234,\n",
       " 4.755782574049441,\n",
       " 6.251380256960146,\n",
       " 6.9331228769545845,\n",
       " 5.502216059333219,\n",
       " 8.747951269049565,\n",
       " 0.3774950158213879,\n",
       " 9.14456861111299,\n",
       " 0.9296579889868868,\n",
       " -0.5672934744585953,\n",
       " 10.19660451808586,\n",
       " 4.114472690252399,\n",
       " 4.562770361257075,\n",
       " 2.9578367569449644,\n",
       " 3.3386503845770283,\n",
       " 4.048446780049335,\n",
       " 1.274592294876397,\n",
       " 6.2627624154445085,\n",
       " 7.856316223243163,\n",
       " 9.637882976162095,\n",
       " 10.682655003862138,\n",
       " 5.9993562168238475,\n",
       " 2.315539261607267,\n",
       " 4.108838481845712,\n",
       " 4.994386668922783,\n",
       " 7.895314748068478,\n",
       " 6.241409018227212,\n",
       " 6.986388995451838,\n",
       " 5.008716658119738,\n",
       " 1.429484620217267,\n",
       " 6.755314904159038,\n",
       " 1.9190928799992168,\n",
       " 4.945834289174316,\n",
       " 4.5082465706505594]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.uniform(low=0.0, high=1.0, size=100)\n",
    "epsilon = np.random.normal(size = 100)\n",
    "\n",
    "\n",
    "y = [(10*x_i + epsilon_i) for x_i, epsilon_i in zip(x, epsilon)]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Implementing OLS regression\n",
    "Write a function that takes as input a numpy vector of target values $y$, and a matrix of predictors $X$, and returns the parameter vector $\\beta$ resulting from OLS regression. Apply this function to fit a model on your artificial data, compute the predictions, and add the resulting regression line to the plot from a). Remember to add a constant term!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(y, X):\n",
    "    X_with_constant = sm.add_constant(X)\n",
    "    #print(X_with_constant)\n",
    "    model = sm.OLS(y, X_with_constant)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "    return results.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.895\n",
      "Model:                            OLS   Adj. R-squared:                  0.894\n",
      "Method:                 Least Squares   F-statistic:                     837.0\n",
      "Date:                Sun, 04 Sep 2022   Prob (F-statistic):           8.51e-50\n",
      "Time:                        19:31:31   Log-Likelihood:                -132.65\n",
      "No. Observations:                 100   AIC:                             269.3\n",
      "Df Residuals:                      98   BIC:                             274.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0850      0.189      0.449      0.654      -0.291       0.460\n",
      "x1             9.9042      0.342     28.930      0.000       9.225      10.584\n",
      "==============================================================================\n",
      "Omnibus:                        0.772   Durbin-Watson:                   1.949\n",
      "Prob(Omnibus):                  0.680   Jarque-Bera (JB):                0.854\n",
      "Skew:                          -0.098   Prob(JB):                        0.652\n",
      "Kurtosis:                       2.592   Cond. No.                         4.64\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.08495516, 9.90423412])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Diagnostics 1: The Bootstrap\n",
    "\n",
    "Based on your regression function, write a function that again takes as input a predictor matrix $X$ and a target column $y$, plus a integer $N$, and bootstraps the data $N$ times to compute the 95% confidence interval for each parameter. Specifically, return one parameter vector for the bottom beta values, and one parameter vector for the top values. \n",
    "Apply this function to estimate the confidence intervals on our artificial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Diagnostics 2: The $R^2$ score.\n",
    "\n",
    "Write a function that takes as input a ground truth vector y, its prediction y_hat, and computes the $R^2$ value of that prediction! Does your model explain most of the variance in the artificial data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Predicting Student Performance\n",
    "\n",
    "We revisit the student performance dataset from the exercise two weeks ago, and aim to estimate the exam performance in math. In this task you may use statsmodels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Data Preprocessing\n",
    "\n",
    "Load the student performance data into a dataframe. Since we want to estimate students performance in math, separate this column from the dataframe. On the remaining columns, transform, i.e. dummy-code all categorical columns as explained in lecture. Further, check for collinearities. If a pair of highly correlated columns (i.e. pearson correlation > 0.9) is given, remove one of these columns from the predictors. Remember to add a constant term afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>parental_level_of_education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test_preparation_course</th>\n",
       "      <th>math_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>writing_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>female</td>\n",
       "      <td>group E</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender race_ethnicity parental_level_of_education         lunch  \\\n",
       "0    female        group B           bachelor's degree      standard   \n",
       "1    female        group C                some college      standard   \n",
       "2    female        group B             master's degree      standard   \n",
       "3      male        group A          associate's degree  free/reduced   \n",
       "4      male        group C                some college      standard   \n",
       "..      ...            ...                         ...           ...   \n",
       "995  female        group E             master's degree      standard   \n",
       "996    male        group C                 high school  free/reduced   \n",
       "997  female        group C                 high school  free/reduced   \n",
       "998  female        group D                some college      standard   \n",
       "999  female        group D                some college  free/reduced   \n",
       "\n",
       "    test_preparation_course  math_score  reading_score  writing_score  \n",
       "0                      none          72             72             74  \n",
       "1                 completed          69             90             88  \n",
       "2                      none          90             95             93  \n",
       "3                      none          47             57             44  \n",
       "4                      none          76             78             75  \n",
       "..                      ...         ...            ...            ...  \n",
       "995               completed          88             99             95  \n",
       "996                    none          62             55             55  \n",
       "997               completed          59             71             65  \n",
       "998               completed          68             78             77  \n",
       "999                    none          77             86             86  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"StudentsPerformance.csv\")\n",
    "\n",
    "#for column in df.columns:\n",
    "#    column = \"_\".join(column.split())\n",
    "#    print(column)\n",
    "\n",
    "\n",
    "df.columns = [\"_\".join(column.split()) for column in df.columns]\n",
    "df.columns = [\"_\".join(column.split(\"/\")) for column in df.columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Learning a simple regression model\n",
    "\n",
    "Apply statsmodels to estimate the exam performance in math from all other columns, without any column interactions. Remember to use a constant term, and properly transform categorical variables. Which significant effects do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Adding interactions\n",
    "Apply statsmodels to fit a regression model that in addition to the previous model further considers an interaction term between the test preparation course and each of the continuous columns that are left from the preprocessing. Thus, first add these columns to your predictor matrix, and then compute the corresponding model.\n",
    "Does this interaction yield an improvement or rather cause problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Checking Residuals\n",
    "Create a residual plot of both your models and give an interpretation of what you observe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
