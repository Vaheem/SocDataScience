{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Basic Statistics and Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Statistical Analysis on the Iris Dataset\n",
    "\n",
    "We reconsider the Iris dataset that was introduced in last week's exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_weight</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width   petal_weight  petal_width        class\n",
       "0           5.1          3.5            1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0            1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2            1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1            1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6            1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"iris.data\", names = [\"sepal_length\", \"sepal_width\",\" petal_weight\", \"petal_width\", \"class\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Descriptive Statistics\n",
    "Use pandas built-in functions to compute the mean, variance, minimum and maximum of the _sepal length_ of all plants in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.843333333333335\n",
      "0.6856935123042505\n",
      "4.3\n",
      "7.9\n"
     ]
    }
   ],
   "source": [
    "print(df.sepal_length.mean())\n",
    "print(df.sepal_length.var())\n",
    "print(df[\"sepal_length\"].min())\n",
    "print(df.loc[:,\"sepal_length\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Implementing the median\n",
    "\n",
    "Write a function that takes a (numerical) column of a pandas dataframe as input and computes its median. Use it to compute the median of the _petal width_ and compare it to the output of pandas built-in median function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3\n",
      "1.3\n"
     ]
    }
   ],
   "source": [
    "def median(col):\n",
    "    \"\"\"\n",
    "    :param col: pandas series, corresponding to the column we want to compute the median of\n",
    "    :\n",
    "    :return: the resulting median value as float \n",
    "    \"\"\"\n",
    "    \n",
    "    m_ind = int((len(col)-1)/2)\n",
    "    # convert to numpy to avoid hassle with panda index\n",
    "    col = col.to_numpy()\n",
    "    col.sort()\n",
    "    return col[m_ind]\n",
    "    \n",
    "print(median(df.loc[:,\"petal_width\"]))\n",
    "print(df.petal_width.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Pearson's Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes two (numerical) pandas columns as input and returns their Pearson correlation coefficient. Do not use any pandas/numpy/scipy built-ins. Apply your function to compute the correlation between _sepal length_ and _sepal width_. Check it for correctness by applying the corresponding [scipy built-in](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(x, y):\n",
    "    \"\"\"\n",
    "    :param x: pandas series\n",
    "    :param y: pandas series\n",
    "    :\n",
    "    :return: the resulting pearson correlation\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(x)\n",
    "    x_hat, y_hat = sum(x)/n, sum(y)/n\n",
    "    dx, dy = [v-x_hat for v in x], [v-y_hat for v in y]\n",
    "    s_x, s_y = (sum(d**2 for d in dx)/n)**.5, (sum(d**2 for d in dy)/n)**.5\n",
    "    \n",
    "    return sum(dx[i]*dy[i]/n for i in range(n))/(s_x*s_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10936924995064931\n",
      "(-0.10936924995064935, 0.1827652152713699)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(pearson(df.sepal_length,df.sepal_width))\n",
    "print(pearsonr(df.sepal_length,df.sepal_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean _sepal width_ for all plants that are classed as _Iris-versicolor_ and for all plants that are classed as _Iris-virginica_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7700000000000005\n",
      "2.9739999999999998\n"
     ]
    }
   ],
   "source": [
    "mean_versicolor = df.loc[df.loc[:,\"class\"] == \"Iris-versicolor\"].sepal_width.mean()\n",
    "mean_virginica = df.loc[df.loc[:,\"class\"] == \"Iris-virginica\"].sepal_width.mean()\n",
    "\n",
    "\n",
    "print(mean_versicolor)\n",
    "print(mean_virginica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the null hypothesis that there is no difference in the means of the groups. Compute the corresponding _p_-value by shuffling the class labels 100000 times and computing the difference in means each of these times. Do you oberve a significant difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2039999999999993\n"
     ]
    }
   ],
   "source": [
    "# since the null hypothesis formulated above does not specify a direction of the difference, \n",
    "# i.e., whether the width of versicolor is lower or higher than of virginica, we use the absolute difference\n",
    "# -> two-sided test\n",
    "\n",
    "mean_diff = abs(mean_versicolor-mean_virginica)\n",
    "print(mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical p-value: 0.00201\n"
     ]
    }
   ],
   "source": [
    "col = df.loc[df.loc[:,\"class\"] != \"Iris-setosa\",\"sepal_width\"].to_numpy()\n",
    "\n",
    "ct = 0\n",
    "for _ in range(100000):\n",
    "    np.random.shuffle(col)\n",
    "    \n",
    "    # abuse that in original column, the elements were soted by class, and evenly distributed\n",
    "    # -> 50 instances per class\n",
    "    diff = abs(np.mean(col[:50]) - np.mean(col[50:]))\n",
    "    if diff > mean_diff:\n",
    "        ct+=1\n",
    "        \n",
    "p_value = ct/100000\n",
    "print(\"Empirical p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The p-value is below 0.01, and thus we observe a significant difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) The Bootstrap\n",
    "\n",
    "We consider the _sepal width_ of all plants in the data that are classed as _Iris-setosa_. Compute the 95% confidence interval of their mean by bootstrapping the data 10000 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.418\n"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "\n",
    "sw = df.loc[df.loc[:,\"class\"] == \"Iris-setosa\",\"sepal_width\"].to_numpy()\n",
    "\n",
    "print(np.mean(sw))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval: (3.312,3.5239999999999996)\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "for i in range(10000):\n",
    "    sample = sw[choices(range(50), k=50)]\n",
    "    means.append(np.mean(sample))\n",
    "    \n",
    "means = np.sort(means)\n",
    "print(\"Confidence interval: (\" + str(means[249]) +\",\"+ str(means[9749]) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: A Dice Game\n",
    "Consider the following game of dices: You roll 5 dice, and you get points for each die you roll.\n",
    "For each one, you get 100 points, for each six, you get 60 points, for all other numbers just the shown value (e.g., you get 3 points for a 3). Your total score is the sum of these points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Simulation and Plotting\n",
    "\n",
    "Simulate the game 100,000 times, and save both every single dice roll as well as the resulting score for each of the 100000 rounds. Use [matplotlib's histogram function](https://matplotlib.org/3.3.2/api/_as_gen/matplotlib.pyplot.hist.html) to plot a histogram of outcomes with 100 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[113, 75, 78, 116, 131, 73, 212, 112, 362, 169]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.array([0,100,2,3,4,5,60])\n",
    "\n",
    "def score_roll(roll):\n",
    "    return np.sum(scores[roll])\n",
    "\n",
    "\n",
    "#roll 100,000 times and store the results in an array\n",
    "rolls = [choices(range(1,7),k=5) for _ in range(100000)]\n",
    "scores = [score_roll(roll) for roll in rolls]\n",
    "\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.5800e+03, 8.8230e+03, 2.8650e+03, 1.1000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 6.8000e+01, 6.8520e+03, 9.2530e+03, 3.1600e+02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.3170e+03, 1.1162e+04, 9.3200e+02, 4.9800e+02, 6.4290e+03,\n",
       "        1.2480e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.8200e+02, 1.1315e+04, 5.0340e+03, 0.0000e+00,\n",
       "        7.4600e+02, 1.2860e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.0680e+03, 4.1070e+03, 0.0000e+00, 1.1550e+03, 5.0740e+03,\n",
       "        0.0000e+00, 0.0000e+00, 2.4600e+02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 3.7500e+02, 5.2920e+03, 3.7100e+02, 0.0000e+00,\n",
       "        7.6100e+02, 2.6400e+02, 0.0000e+00, 0.0000e+00, 1.0000e+01,\n",
       "        1.6650e+03, 3.8900e+02, 0.0000e+00, 7.6000e+02, 7.9000e+02,\n",
       "        0.0000e+00, 0.0000e+00, 6.1000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.7500e+02, 7.3900e+02, 0.0000e+00, 0.0000e+00,\n",
       "        1.2500e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.5600e+02, 0.0000e+00, 0.0000e+00, 1.3100e+02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 6.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0000e+00]),\n",
       " array([ 10. ,  14.9,  19.8,  24.7,  29.6,  34.5,  39.4,  44.3,  49.2,\n",
       "         54.1,  59. ,  63.9,  68.8,  73.7,  78.6,  83.5,  88.4,  93.3,\n",
       "         98.2, 103.1, 108. , 112.9, 117.8, 122.7, 127.6, 132.5, 137.4,\n",
       "        142.3, 147.2, 152.1, 157. , 161.9, 166.8, 171.7, 176.6, 181.5,\n",
       "        186.4, 191.3, 196.2, 201.1, 206. , 210.9, 215.8, 220.7, 225.6,\n",
       "        230.5, 235.4, 240.3, 245.2, 250.1, 255. , 259.9, 264.8, 269.7,\n",
       "        274.6, 279.5, 284.4, 289.3, 294.2, 299.1, 304. , 308.9, 313.8,\n",
       "        318.7, 323.6, 328.5, 333.4, 338.3, 343.2, 348.1, 353. , 357.9,\n",
       "        362.8, 367.7, 372.6, 377.5, 382.4, 387.3, 392.2, 397.1, 402. ,\n",
       "        406.9, 411.8, 416.7, 421.6, 426.5, 431.4, 436.3, 441.2, 446.1,\n",
       "        451. , 455.9, 460.8, 465.7, 470.6, 475.5, 480.4, 485.3, 490.2,\n",
       "        495.1, 500. ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use matplotlib/pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist (scores, bins=100, edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Hypothesis Testing pt. 2\n",
    "Assume that in your initial roll, you scored 268. Is this significantly above what is to be expected? Compute the corresponding _p_-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08589\n"
     ]
    }
   ],
   "source": [
    "p_value = np.sum([1 for x in scores if x >= 268]) / len(scores)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** In this case we have that $p>0.05$, so this is not a statistically significant outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Conditional Probability and Bayes Theorem\n",
    "\n",
    "Based on your simulation, give an estimation of the probability of scoring over 100 points, given that you did not roll a single 1. Afterwards, estimate the probability of scoring over 100 points, and apply your previous results and Bayes Theorem to compute the probability of not rolling a 1 given that you score over 100 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(score>100|no 1 rolled) = 0.26007307797469614\n"
     ]
    }
   ],
   "source": [
    "# probability of scoring over 150 points without rolling a 1\n",
    "p1 = sum(1 if scores[i] > 100 and 1 not in rolls[i] else 0 for i in range(100000))/100000\n",
    "\n",
    "# probability of not rolling a 1\n",
    "p2 = sum(1 if 1 not in roll else 0 for roll in rolls)/100000\n",
    "\n",
    "p_cond = p1/p2\n",
    "\n",
    "print(\"P(score>100|no 1 rolled) = \" + str(p_cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(no 1 rolled | score>100) = 0.14897767399476022\n"
     ]
    }
   ],
   "source": [
    "p3 = sum(1 if score > 100 else 0 for score in scores)/100000\n",
    "\n",
    "print(\"P(no 1 rolled | score>100) = \" + str(p_cond*p2/p3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
